# Hourly scraping
name: thb_scrape

# inspired by: https://www.programmingwithr.com/daily-stock-gainers-automated-web-scraping-in-r-with-github-actions/

# Controls when the action will run.
on:
  # push:
    # branches: main
  schedule:
    - cron:  '0 15 * * *'
    # see: https://crontab.guru/


jobs: 
  autoscrape:
    # The type of runner that the job will run on
    runs-on: macos-latest

    # Load repo and install R
    steps:
    - uses: actions/checkout@master
    - uses: r-lib/actions/setup-r@master

    # Set-up R
    - name: Install packages
      run: |
        R -e 'install.packages(c("tibble", "magrittr", "stringr", "dplyr", "tidyr", "purrr", "rvest"))'
    # Run R script
    - name: Scrape
      run: Rscript scrape_thb.R
      
 # Add new files in data folder, commit along with other modified files, push
    - name: Commit files
      run: |
        git config --local user.name actions-user
        git config --local user.email "actions@github.com"
        git add data/*
        git commit -am "GH ACTION Headlines $(date)"
        git push origin main
      env:
        REPO_KEY: ${{secrets.GITHUB_TOKEN}}
        username: github-actions
